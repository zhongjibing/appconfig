Setting up a Single Node Cluster.

Required Software
  java
  ssh
  pdsh

Download and unpack the downloaded Hadoop distribution. In the distribution, edit the file etc/hadoop/hadoop-env.sh to define some parameters as follows:
  # set to the root of your Java installation
  export JAVA_HOME=/usr/java/latest

Try the following command:
  $ bin/hadoop
This will display the usage documentation for the hadoop script.

Configuration
etc/hadoop/core-site.xml:

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
etc/hadoop/hdfs-site.xml:

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

Setup passphraseless ssh

Now check that you can ssh to the localhost without a passphrase:
  $ ssh localhost
If you cannot ssh to localhost without a passphrase, execute the following commands:
  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
  $ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  $ chmod 0600 ~/.ssh/authorized_keys

Format the filesystem:
  $ bin/hdfs namenode -format

Start NameNode daemon and DataNode daemon:
  $ sbin/start-dfs.sh

The hadoop daemon log output is written to the $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs).

Browse the web interface for the NameNode; by default it is available at:

NameNode - http://localhost:9870/

When youâ€™re done, stop the daemons with:
  $ sbin/stop-dfs.sh

